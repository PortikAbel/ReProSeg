hydra:
  run:
    dir: ${oc.env:LOG_ROOT}/reproseg/${now:%Y-%m-%d-%H-%M-%S}  # hydra output dir

# Seed and Dataloader
seed: 1                           # Random seed. Note: nondeterminism may still occur. See PyTorch docs on randomness.
num_workers: 8                    # Number of workers in dataloaders.

# GPU Settings
gpu_ids: 0                      # ID of GPU(s). Can be comma-separated (e.g., "0,1").
disable_gpu: false                # Disable GPU usage and force CPU if set.

# Logging
log_dir: ${oc.env:LOG_ROOT}/reproseg/${now:%Y-%m-%d-%H-%M-%S}  # Directory to save logs and outputs.
save_all_models: false            # Save the model at every epoch (default: only best model).

# Dataset
dataset: CityScapes               # Dataset to train ReProSeg on.
validation_size: 0.0              # Fraction of training data to use as validation (e.g., 0.2 for partimagenet).
disable_normalize: false          # Disable normalization of images if set.

# Model
net: deeplab_v3                   # Backbone network (e.g., "deeplab_v3").
model_checkpoint: null            # Path to pretrained ReProSeg checkpoint to resume from.

skip_training: false              # Skips training and only visualizes prototypes and predictions.

# Network Parameters
batch_size: 4                    # Minibatch size (will be multiplied by the number of GPUs).
train_backbone_during_pretrain: false  # Whether to train the full backbone during pretraining.
epochs_pretrain: 10              # Epochs for prototype pretraining (stage 1).
epochs: 60                       # Total training epochs (stage 2).
epochs_freeze: 10                # Epochs where backbone is frozen and only classifier is trained.
epochs_finetune: 3                # Finetuning epochs with frozen backbone.
epoch_start: 1                    # Starting epoch (for resuming).
num_features: 0                   # Number of prototypes. 0 = use backbone output channels.
disable_pretrained: false         # Initialize backbone randomly instead of using pretrained weights.
bias: false                       # Include a bias in classification layer if true.

# Optimizer
optimizer: Adam                   # Optimizer (e.g., Adam, SGD).
lr: 0.05                          # Learning rate for prototype â†’ class weights.
lr_block: 0.0005                  # Learning rate for final backbone layers.
lr_net: 0.0005                    # Learning rate for rest of backbone.
weight_decay: 0.0                 # Weight decay for optimizer.

# Loss
align_loss: 1.0                   # Ensures prototypes of similar images are aligned.
jsd_loss: 0.0                     # Jensen-Shannon Divergence: enforces prototype diversity.
tanh_loss: 0.0                    # Ensures each prototype is activated at least once per batch.
unif_loss: 0.0                    # Optional uniformity loss (see https://www.tongzhouwang.info/hypersphere/).
variance_loss: 0.0                # Prototype feature variance regularizer (https://arxiv.org/abs/2105.04906).
classification_loss: 1.0          # Standard classification loss weight.
criterion: dice           # Loss function type: ["weighted_nll", "dice"].

# Visualization
visualize_prototypes: false       # Visualize top-k activations of each prototype.
visualize_top_k: 10               # Number of top-k activations to visualize per prototype.
visualize_predictions: false      # Visualize predictions on test set and learned prototypes.

# Interpretability
consistency_score: false          # Compute consistency score for interpretability.
consistency_threshold: 0.7        # Threshold above which a prototype is considered consistent.
